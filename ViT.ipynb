{"cells":[{"id":"7e04d5fb-9ad6-4dae-94ea-98029473a757","cell_type":"markdown","source":"","metadata":{}},{"id":"8b6fc9ed-be4a-47a2-9936-a5038b8f514e","cell_type":"code","source":"# ==========================================\n# Cell 1: å…¨å±€è¶…å‚æ•°ä¸è·¯å¾„é…ç½®åŒº (æ‰€æœ‰å¯è°ƒå‚æ•°å‡åœ¨æ­¤å¤„)\n# ==========================================\n\n# 1. è·¯å¾„é…ç½® (è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹åŸºç¡€è·¯å¾„)\nDATA_BASE_DIR = \"./data\"          # å­˜æ”¾æ‰€æœ‰æŠ½å¸§å›¾ç‰‡çš„æ ¹ç›®å½•\nCSV_BASE_DIR = \"./annotations\"    # å­˜æ”¾æ‰€æœ‰CSVæ ‡æ³¨æ–‡ä»¶çš„æ ¹ç›®å½•\n\n# 2. è®­ç»ƒè¶…å‚æ•°\nBATCH_SIZE = 32                   # æ‰¹æ¬¡å¤§å° (å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œå¯è°ƒå°è‡³ 16 æˆ– 8)\nEPOCHS = 20                       # è®­ç»ƒæ€»è½®æ•°\nLEARNING_RATE = 1e-4              # åˆå§‹å­¦ä¹ ç‡\nWEIGHT_DECAY = 1e-4               # æƒé‡è¡°å‡ (é˜²æ­¢è¿‡æ‹Ÿåˆ)\nEARLY_STOPPING_PATIENCE = 5       # æ—©åœè€å¿ƒå€¼ (è¿ç»­5ä¸ªepochéªŒè¯é›†å‡†ç¡®ç‡æœªæå‡åˆ™åœæ­¢)\n\n# 3. å›¾åƒå°ºå¯¸ä¸æ¨¡å‹å‚æ•°\nIMAGE_SIZE = 224                  # ViTçš„æ ‡å‡†è¾“å…¥åˆ†è¾¨ç‡ (è¯·å‹¿éšæ„ä¿®æ”¹ï¼Œé™¤éä½¿ç”¨384çš„é¢„è®­ç»ƒæƒé‡)\nMODEL_NAME = \"vit_base_patch16_224\" # timmåº“ä¸­çš„ViTæ¨¡å‹åç§°\nNUM_CLASSES = 9                   # æ™¯åˆ«ç±»åˆ«æ€»æ•° (0åˆ°8ï¼Œå…±9ç±»)\n\n# 4. æ™¯åˆ«ç±»åˆ«æ˜ å°„å­—å…¸ (æ ¹æ® README.txt è®¾å®š)\n# æ³¨æ„ï¼šä»£ç é€»è¾‘ä¸­ä¼šè‡ªåŠ¨è¿‡æ»¤æ‰ 9 (Not available) çš„æ•°æ®\nCLASS_MAPPING = {\n    0: 'FS (Foreground shot)',\n    1: 'ECU (Extreme close up)',\n    2: 'CU (Close up)',\n    3: 'MCU (Medium close up)',\n    4: 'MS (Medium shot)',\n    5: 'MLS (Medium long shot)',\n    6: 'LS (Long shot)',\n    7: 'ELS (Extreme long shot)',\n    8: 'INS (Insert)'\n}\n\n# 5. ç¡¬ä»¶ä¸éšæœºç§å­é…ç½®\nSEED = 42                         # å›ºå®šéšæœºç§å­ï¼Œä¿è¯å®éªŒå¯å¤ç°\nVAL_SPLIT_RATIO = 0.2             # éªŒè¯é›†åˆ’åˆ†æ¯”ä¾‹ (20%ç”¨äºéªŒè¯)","metadata":{},"execution_count":null},{"id":"5c04229f-533c-4ceb-bfbd-f48b72a97dd9","cell_type":"code","source":"# ==========================================\n# Cell 2: å¯¼å…¥æ‰€æœ‰ä¾èµ–åº“å¹¶é…ç½®ç¡¬ä»¶ç¯å¢ƒ\n# ==========================================\nimport os\nimport glob\nimport torch\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nimport timm\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport random\n\n# å›ºå®šéšæœºç§å­\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\n# æ£€æµ‹å¹¶é…ç½®è®¾å¤‡ (ä¼˜å…ˆä½¿ç”¨ GPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"ğŸ¬ å½“å‰è®­ç»ƒè®¾å¤‡: {device}\")","metadata":{},"execution_count":null},{"id":"a5ff417e-9f00-4c54-bace-c73752c4264a","cell_type":"code","source":"# ==========================================\n# Cell 3: è‡ªå®šä¹‰æ™¯åˆ«æ•°æ®é›†è¯»å–é€»è¾‘\n# ==========================================\n\nclass ShotScaleDataset(Dataset):\n    def __init__(self, csv_dir, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.transform = transform\n        self.samples = []\n        \n        # éå†æ‰€æœ‰CSVæ–‡ä»¶\n        csv_files = glob.glob(os.path.join(csv_dir, \"*.csv\"))\n        for csv_path in csv_files:\n            filename = os.path.basename(csv_path)\n            # æ ¹æ® README è§„åˆ™è§£æç›®å½•å: {year}_{director}_-_{title}.csv\n            # ä¾‹å¦‚: 1950_antonioni_-_cronaca_di_un_amore.csv\n            movie_folder_name = filename.replace(\".csv\", \"\")\n            director = movie_folder_name.split(\"_-_\")[0].split(\"_\", 1)[1]\n            \n            # æ„å»ºè¯¥ç”µå½±å›¾ç‰‡çš„å­˜æ”¾è·¯å¾„\n            img_folder_path = os.path.join(data_dir, director, movie_folder_name)\n            \n            # è¯»å–CSV\n            df = pd.read_csv(csv_path)\n            \n            # è¿‡æ»¤æ‰ shotscale == 9 (NA) çš„è¡Œ\n            df = df[df['shotscale'] != 9]\n            \n            for index, row in df.iterrows():\n                # æ ¹æ®CSVçš„è¡Œç´¢å¼•(å…¶å®å°±æ˜¯ç¬¬ä¸€åˆ— Unnamed: 0) è®¡ç®—å›¾ç‰‡å\n                # å‡è®¾ç´¢å¼• 0 å¯¹åº” 00001.jpg\n                img_idx = int(row.iloc[0]) + 1\n                img_name = f\"{img_idx:05d}.jpg\"\n                img_path = os.path.join(img_folder_path, img_name)\n                \n                label = int(row['shotscale'])\n                \n                # å°†æœ‰æ•ˆè·¯å¾„å’Œæ ‡ç­¾å­˜å…¥åˆ—è¡¨\n                self.samples.append((img_path, label))\n                \n        print(f\"âœ… æˆåŠŸåŠ è½½æ•°æ®é›†ï¼Œå…±æ‰¾åˆ° {len(self.samples)} å¸§æœ‰æ•ˆè®­ç»ƒå›¾åƒã€‚\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        try:\n            image = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            print(f\"âš ï¸ è¯»å–å›¾ç‰‡å¤±è´¥: {img_path}, é”™è¯¯: {e}\")\n            # å¦‚æœå‡ºé”™ï¼Œè¿”å›ä¸€å¼ çº¯é»‘å›¾ä½œä¸ºæ›¿ä»£ï¼Œé¿å…è®­ç»ƒä¸­æ–­\n            image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), (0, 0, 0))\n            \n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label\n\n# ------------------------------------------\n# å®šä¹‰ Transformer ä¸“å±çš„æ•°æ®é¢„å¤„ç†\n# âš ï¸ åšå†³ä¸ä½¿ç”¨ RandomCropï¼Œä¸¥æ ¼ä¿æŠ¤å½±è§†åŸå§‹æ„å›¾æ¯”ä¾‹ï¼\n# ------------------------------------------\ndata_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), # ç›´æ¥æ‹‰ä¼¸æˆ–è€…æŒ‰æ¯”ä¾‹ç¼©æ”¾å¡«å……ä»¥åŒ¹é…è¾“å…¥\n    transforms.RandomHorizontalFlip(p=0.5),      # å·¦å³é•œåƒä¸å½±å“æ™¯åˆ«åˆ¤æ–­\n    transforms.ColorJitter(brightness=0.2, contrast=0.2), # æ¨¡æ‹Ÿä¸åŒå…‰ç…§\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNetæ ‡å‡†å½’ä¸€åŒ–\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{},"execution_count":null},{"id":"bb7766da-7f9d-4f7a-97dd-714c4fe9599e","cell_type":"code","source":"# ==========================================\n# Cell 4: å®ä¾‹åŒ– Dataset å¹¶åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n# ==========================================\n\n# åˆå§‹åŒ–å®Œæ•´æ•°æ®é›†\nfull_dataset = ShotScaleDataset(csv_dir=CSV_BASE_DIR, data_dir=DATA_BASE_DIR, transform=data_transforms)\n\n# è®¡ç®—åˆ’åˆ†é•¿åº¦\nval_size = int(len(full_dataset) * VAL_SPLIT_RATIO)\ntrain_size = len(full_dataset) - val_size\n\n# éšæœºåˆ‡åˆ†\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# éªŒè¯é›†éœ€è¦ä½¿ç”¨çº¯å‡€çš„ val_transforms (å»é™¤æ•°æ®å¢å¼º)\nval_dataset.dataset.transform = val_transforms\n\n# åˆ›å»º DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\nprint(f\"ğŸï¸ è®­ç»ƒé›†å›¾åƒæ•°: {train_size} | éªŒè¯é›†å›¾åƒæ•°: {val_size}\")","metadata":{},"execution_count":null},{"id":"abe96007-6369-42e8-8186-f28e09caad62","cell_type":"code","source":"# ==========================================\n# Cell 5: æ„å»º Vision Transformer å¹¶æ›¿æ¢åˆ†ç±»å¤´\n# ==========================================\n\n# ä½¿ç”¨ timm ç›´æ¥åŠ è½½é¢„è®­ç»ƒçš„ ViT æ¨¡å‹ï¼Œå¹¶è‡ªåŠ¨å°†è¾“å‡ºç±»åˆ«æ•°ä¿®æ”¹ä¸ºæˆ‘ä»¬çš„ NUM_CLASSES\nmodel = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASSES)\n\n# å°†æ¨¡å‹æ¬è¿åˆ° GPU (æˆ– CPU)\nmodel = model.to(device)\n\nprint(f\"ğŸš€ æ¨¡å‹ {MODEL_NAME} åŠ è½½å®Œæ¯•ï¼Œè¾“å‡ºå±‚å·²è°ƒæ•´ä¸º {NUM_CLASSES} ç±»ã€‚\")","metadata":{},"execution_count":null},{"id":"0af6d85c-ccca-472c-aca5-66a6d194e7e2","cell_type":"code","source":"# ==========================================\n# Cell 6: å®šä¹‰æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡è¡°å‡ç­–ç•¥\n# ==========================================\n\n# äº¤å‰ç†µæŸå¤±å‡½æ•°\ncriterion = nn.CrossEntropyLoss()\n\n# Transformer çš„æ ‡é…ï¼šAdamW ä¼˜åŒ–å™¨\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n# ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨ (è®©å­¦ä¹ ç‡å¹³æ»‘ä¸‹é™)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)","metadata":{},"execution_count":null},{"id":"1f827a8a-44ea-4b12-b5ab-eb021b6d8a9e","cell_type":"code","source":"# ==========================================\n# Cell 7: è®­ç»ƒä¸»å¾ªç¯ (åŒ…å«æ—©åœä¸æœ€ä¼˜æƒé‡ä¿å­˜æœºåˆ¶)\n# ==========================================\n\nbest_val_acc = 0.0\nepochs_no_improve = 0\nbest_model_path = 'best_shotscale_vit.pth'\n\nfor epoch in range(EPOCHS):\n    print(f\"\\n--- Epoch {epoch+1}/{EPOCHS} ---\")\n    \n    # ---------------- è®­ç»ƒé˜¶æ®µ ----------------\n    model.train()\n    train_loss = 0.0\n    train_correct = 0\n    \n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * inputs.size(0)\n        _, preds = torch.max(outputs, 1)\n        train_correct += torch.sum(preds == labels.data)\n        \n    scheduler.step() # æ›´æ–°å­¦ä¹ ç‡\n    \n    epoch_train_loss = train_loss / train_size\n    epoch_train_acc = train_correct.double() / train_size\n    \n    # ---------------- éªŒè¯é˜¶æ®µ ----------------\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    \n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            val_loss += loss.item() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            val_correct += torch.sum(preds == labels.data)\n            \n    epoch_val_loss = val_loss / val_size\n    epoch_val_acc = val_correct.double() / val_size\n    \n    print(f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.4f}\")\n    print(f\"Val Loss:   {epoch_val_loss:.4f} | Val Acc:   {epoch_val_acc:.4f}\")\n    \n    # ---------------- æ—©åœä¸ä¿å­˜æœ€ä¼˜æƒé‡ ----------------\n    if epoch_val_acc > best_val_acc:\n        best_val_acc = epoch_val_acc\n        epochs_no_improve = 0\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"ğŸŒŸ éªŒè¯é›†å‡†ç¡®ç‡åˆ›æ–°é«˜! æƒé‡å·²ä¿å­˜è‡³ {best_model_path}\")\n    else:\n        epochs_no_improve += 1\n        print(f\"âš ï¸ éªŒè¯é›†å‡†ç¡®ç‡æœªæå‡ (ç´¯è®¡ {epochs_no_improve} ä¸ª Epoch)\")\n        \n    if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n        print(f\"ğŸ›‘ è§¦å‘æ—©åœæœºåˆ¶ï¼Œè®­ç»ƒç»“æŸï¼\")\n        break","metadata":{},"execution_count":null},{"id":"68899826-0a12-423d-8982-637ff6b46f39","cell_type":"code","source":"# ==========================================\n# Cell 8: åŠ è½½æœ€ä¼˜æƒé‡ï¼Œè¾“å‡ºè¯„ä¼°æŠ¥å‘Šä¸æ··æ·†çŸ©é˜µ\n# ==========================================\n\n# åŠ è½½æœ€å¥½çš„æ¨¡å‹\nmodel.load_state_dict(torch.load(best_model_path))\nmodel.eval()\n\nall_preds = []\nall_labels = []\n\nprint(\"æ­£åœ¨ç”Ÿæˆæœ€ç»ˆè¯„ä¼°æŠ¥å‘Šï¼Œè¯·ç¨å€™...\")\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        \n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# è·å–çœŸå®å­˜åœ¨çš„ç±»åˆ«åç§°ç”¨äºç»˜å›¾\ntarget_names = [CLASS_MAPPING[i] for i in range(NUM_CLASSES) if i in set(all_labels)]\n\n# æ‰“å°åˆ†ç±»æŠ¥å‘Š\nprint(\"\\nğŸ“ åˆ†ç±»æŠ¥å‘Š (Classification Report):\")\nprint(classification_report(all_labels, all_preds, target_names=target_names))\n\n# ç»˜åˆ¶æ··æ·†çŸ©é˜µ\ncm = confusion_matrix(all_labels, all_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=target_names, yticklabels=target_names)\nplt.title('Shot Scale Classification Confusion Matrix')\nplt.ylabel('True Shot Scale')\nplt.xlabel('Predicted Shot Scale')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null}],"metadata":{},"nbformat":4,"nbformat_minor":5}